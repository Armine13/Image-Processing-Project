\section{Introduction}

Nowadays, one of the main challenges of medicine and engineering is to develop tools for supporting the medical diagnosis. According to the World Health Organization (WHO), about 15\% of the population's deaths between 2010 and 2020 will be caused by Non-Communicating Diseases (NCD), such as cardiovascular diseases, diabetes, cancer and chronic respiratory diseases~\cite{who}. Thus, the target of this medical tools is to detect timely these diseases such that they can be cured or controlled.  %%Need to build a bridge between this parag. and the next one.

In particular, diabetes detection has been carried out through Retinopathy Image Analysis (RIA). Fundus cameras, scanning lasers, angiography, and, more recently, Optical Coherence Tomography (OCT) are some techniques to acquire retinopathy images. It is important to be aware that these images may be corrupted by noise during the acquisition process. This is due to limitations of sensor capabilities and characteristics, transmission issues, among other facts. As a result, low-quality images, which may not be suitable for medical analysis, are obtained. 

There are different types of noise arising during the acquisition process and also varied techniques trying to overcome them. The criteria for deciding which algorithm to use usually depends on the specific features and constraints of the scenario. Ideally, the type and level of noise are known beforehand. However, most of the time, the case is the opposite and estimation and characterisation of the noise are required. Under this perspective, there are two questions that should be answered before deciding how to address the situation:
(1) Is there any a priori knowledge about the situation? The selection of denoising techniques is fundamental and it can be guided by knowledge of the data to process. Selecting wrongly an algorithm may distort the image instead of improving its quality. (2) What is the goal? There are different approaches for image denoising, but some of them are not suitable for some applications. For instance, Weiner filter is used for removing noise in the sense of Mean Square Error (MSE) but it is not desired for applications in which the visual perception is the target. Having this in mind, there is no algorithm capable of denoising every image and, thus,  expectations should be clear before addressing the problem.

In this paper, an evaluation of different state-of-the-art algorithms for noise removal is presented. The paper is organized as follows. Considered algorithms are described and examined in Section \ref{sc:state-of-the-art}. Synthetic and retinopathy datasets for performing the experimental validation are introduced in Section \ref{sc:experimental-validation}. The considered algorithms are tested following the experimental validation and the final results are analysed in Section \ref{sc:results}. Finally, some final remarks and future work are presented in Section \ref{sc:final-remarks}. 